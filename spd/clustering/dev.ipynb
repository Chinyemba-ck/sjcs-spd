{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from muutils.dbg import dbg_auto\n",
    "\n",
    "from spd.clustering.activations import component_activations, process_activations\n",
    "from spd.clustering.merge import compute_merge_costs, merge_iteration\n",
    "from spd.clustering.merge_matrix import GroupMerge\n",
    "from spd.experiments.resid_mlp.resid_mlp_dataset import ResidualMLPDataset\n",
    "from spd.models.component_model import ComponentModel\n",
    "from spd.utils.data_utils import DatasetGeneratedDataLoader\n",
    "\n",
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# magic autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint from /home/miv/projects/MATS/spd/wandb/5mk5h1lk/files/resid_mlp.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m component_model, cfg, path = \u001b[43mComponentModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwandb:goodfire/spd/runs/r2t6m3kr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m component_model.to(DEVICE);\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MATS/spd/spd/models/component_model.py:361\u001b[39m, in \u001b[36mComponentModel.from_pretrained\u001b[39m\u001b[34m(cls, path)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.pretrained_model_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m target_model_unpatched = load_pretrained(\n\u001b[32m    357\u001b[39m     path_to_class=config.pretrained_model_class,\n\u001b[32m    358\u001b[39m     model_path=config.pretrained_model_path,\n\u001b[32m    359\u001b[39m     model_name_hf=config.pretrained_model_name_hf,\n\u001b[32m    360\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m \u001b[43mtarget_model_unpatched\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m()\n\u001b[32m    362\u001b[39m target_model_unpatched.requires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    364\u001b[39m comp_model = ComponentModel(\n\u001b[32m    365\u001b[39m     target_model=target_model_unpatched,\n\u001b[32m    366\u001b[39m     target_module_patterns=config.target_module_patterns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    370\u001b[39m     pretrained_model_output_attr=config.pretrained_model_output_attr,\n\u001b[32m    371\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "component_model, cfg, path = ComponentModel.from_pretrained(\"wandb:goodfire/spd/runs/r2t6m3kr\")\n",
    "component_model.to(DEVICE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES: int = 512\n",
    "\n",
    "dataset = ResidualMLPDataset(\n",
    "    n_features=component_model.model.config.n_features,\n",
    "    feature_probability=cfg.task_config.feature_probability,\n",
    "    device=DEVICE,\n",
    "    calc_labels=False,  # Our labels will be the output of the target model\n",
    "    label_type=None,\n",
    "    act_fn_name=None,\n",
    "    label_fn_seed=None,\n",
    "    label_coeffs=None,\n",
    "    data_generation_type=cfg.task_config.data_generation_type,\n",
    "    # synced_inputs=synced_inputs,\n",
    ")\n",
    "\n",
    "dbg_auto(\n",
    "    dict(\n",
    "        n_features=dataset.n_features,\n",
    "        feature_probability=dataset.feature_probability,\n",
    "        data_generation_type=dataset.data_generation_type,\n",
    "    )\n",
    ")\n",
    "\n",
    "dataloader = DatasetGeneratedDataLoader(dataset, batch_size=N_SAMPLES, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = component_activations(\n",
    "    component_model,\n",
    "    dataloader,\n",
    "    device=DEVICE,\n",
    "    # threshold=0.1,\n",
    ")\n",
    "\n",
    "dbg_auto(ci);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coa = process_activations(\n",
    "    ci,\n",
    "    filter_dead_threshold=0.001,\n",
    "    plots=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\tF_g := \\frac{\\alpha}{n}\n",
    "\t\\Bigg[\n",
    "\t\td(A(g)) \\cdot Q^T \n",
    "\t\t+ Q \\cdot d(A(g))^T\n",
    "\t\t- \\Big(\n",
    "\t\t\tR \\mathbf{1}^T\n",
    "\t\t\t+ \\mathbf{1} R^T + \\alpha^{-1}\n",
    "\t\t\\Big) \n",
    "\t\t\\odot A(g)\n",
    "\t\\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_ident = GroupMerge.identity(n_components=coa[\"n_components_alive\"])\n",
    "gm_ident.plot(figsize=(10, 2), component_labels=coa[\"labels\"])\n",
    "costs = compute_merge_costs(\n",
    "    coact=coa[\"coactivations\"],\n",
    "    merges=gm_ident,\n",
    ")\n",
    "plt.matshow(costs.cpu(), cmap=\"viridis\")\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_bool = coa[\"activations\"] > 0.5\n",
    "plt.matshow(act_bool.cpu().T, cmap=\"viridis\")\n",
    "dbg_auto(act_bool)\n",
    "plt.matshow((act_bool.float().T @ act_bool.float()).cpu(), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spd.clustering.merge import MergeConfig, MergePlotConfig\n",
    "\n",
    "merge_iteration(\n",
    "    activations=coa[\"activations\"],\n",
    "    component_labels=coa[\"labels\"],\n",
    "    merge_config=MergeConfig(\n",
    "        activation_theshold=None,\n",
    "        alpha=0.01,\n",
    "        iters=100,\n",
    "        check_threshold=0.05,\n",
    "        pop_component_prob=0.0,\n",
    "        rank_cost_fn=lambda x: 1.0,\n",
    "        stopping_condition=None,\n",
    "    ),\n",
    "    plot_config=MergePlotConfig(\n",
    "        plot_every=20,\n",
    "        plot_every_min=0,\n",
    "        save_pdf=False,\n",
    "        # pdf_prefix=\"merge_iteration\",\n",
    "        figsize=(16, 3),\n",
    "        figsize_final=(10, 6),\n",
    "        tick_spacing=10,\n",
    "        plot_final=True,\n",
    "    ),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Example Hyperparameter Sweep Usage\n",
    "\n",
    "# Create sweep configuration\n",
    "\n",
    "from spd.clustering.sweep import SweepConfig, run_hyperparameter_sweep\n",
    "\n",
    "sweep_config = SweepConfig(\n",
    "    # activation_thresholds=[0.001, 0.002, 0.005],\n",
    "    activation_thresholds=np.logspace(-4, -1, 4).tolist(),\n",
    "    # check_thresholds=[0.05, 0.1, 0.2],\n",
    "    check_thresholds=np.logspace(-2, 0, 3).tolist(),\n",
    "    # alphas=[0.1, 1.0, 10.0],\n",
    "    alphas=np.logspace(-3, 0, 4).tolist(),\n",
    "    rank_cost_funcs={\n",
    "        # \"constant_1\": lambda _: 1.0,\n",
    "        # \"constant_0.1\": lambda _: 0.1,\n",
    "        # \"constant_0.001\": lambda _: 0.001,\n",
    "        # \"constant_0.01\": lambda _: 0.01,\n",
    "        # \"constant_0.1\": lambda _: 0.1,\n",
    "        \"constant_1\": lambda _: 1.0,\n",
    "        # \"constant_10\": lambda _: 10.0,\n",
    "        # \"constant_100\": lambda _: 100.0,\n",
    "        \"linear\": lambda c: c,\n",
    "        \"log\": lambda c: np.log(c + 1),\n",
    "    },\n",
    "    iters=50,\n",
    ")\n",
    "\n",
    "# Run sweep\n",
    "sweep_results = run_hyperparameter_sweep(coa[\"coactivations\"], sweep_config)\n",
    "\n",
    "print(f\"\\\\n{len(sweep_results) = }\")\n",
    "for i, result in enumerate(sweep_results[:3]):\n",
    "    print(\n",
    "        f\"{i + 1}: thresh={result.activation_threshold}, check={result.check_threshold}, Î±={result.alpha}, rank={result.rank_cost_name}\"\n",
    "    )\n",
    "    print(f\"   iters={result.total_iterations}, groups={result.final_k_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution histories\n",
    "from spd.clustering.sweep import plot_evolution_histories\n",
    "\n",
    "# plot_evolution_histories(\n",
    "#     sweep_results,\n",
    "#     metric='non_diag_costs_min',\n",
    "#     lines_by='alpha',\n",
    "#     cols_by='activation_threshold',\n",
    "#     rows_by='check_threshold',\n",
    "# \tfixed_params={'rank_cost_name': 'constant_0.1'},  # Example fixed parameter\n",
    "# )\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "    metric=\"costs_range\",\n",
    "    cols_by=\"activation_threshold\",\n",
    "    rows_by=\"alpha\",\n",
    "    lines_by=\"check_threshold\",\n",
    "    fixed_params={\"rank_cost_name\": \"constant_1\"},\n",
    ")\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "    metric=\"costs_range\",\n",
    "    cols_by=\"activation_threshold\",\n",
    "    rows_by=\"alpha\",\n",
    "    lines_by=\"check_threshold\",\n",
    "    fixed_params={\"rank_cost_name\": \"linear\"},\n",
    ")\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "    metric=\"costs_range\",\n",
    "    cols_by=\"activation_threshold\",\n",
    "    rows_by=\"alpha\",\n",
    "    lines_by=\"check_threshold\",\n",
    "    fixed_params={\"rank_cost_name\": \"log\"},\n",
    ")\n",
    "\n",
    "# plot_evolution_histories(\n",
    "#     sweep_results,\n",
    "#     metric='non_diag_costs_min',\n",
    "#     lines_by='activation_threshold',\n",
    "#     cols_by='rank_cost_name',\n",
    "#     rows_by='check_threshold',\n",
    "# \tfixed_params={'alpha': 0.001},  # Example fixed parameter\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmaps with smart parameter selection\n",
    "\n",
    "# create_smart_heatmap(\n",
    "#     sweep_results,\n",
    "#     statistic_func=lambda r: r.final_k_groups,\n",
    "#     statistic_name=\"Final Groups\"\n",
    "# )\n",
    "\n",
    "# create_smart_heatmap(\n",
    "#     sweep_results,\n",
    "#     statistic_func=lambda r: r.total_iterations,\n",
    "#     statistic_name=\"Total Iterations\"\n",
    "# )\n",
    "\n",
    "# create_smart_heatmap(\n",
    "#     sweep_results,\n",
    "#     statistic_func=lambda r: r.non_diag_costs_min[-1] if r.non_diag_costs_min else 0,\n",
    "#     statistic_name=\"Final Cost\",\n",
    "#     log_scale=True,\n",
    "#     normalize=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Stopping Condition Examples\n",
    "\n",
    "# Example: Stop when cost reaches 2x original\n",
    "from spd.clustering.sweep import cost_ratio_stopping_condition\n",
    "\n",
    "stop_at_2x = cost_ratio_stopping_condition(2.0)\n",
    "\n",
    "# Run with stopping condition\n",
    "result_with_stop = merge_iteration(\n",
    "    coact=(coa[\"coactivations\"] > 0.002).float().T @ (coa[\"coactivations\"] > 0.002).float(),\n",
    "    activation_mask=coa[\"coactivations\"] > 0.002,\n",
    "    alpha=1.0,\n",
    "    check_threshold=0.1,\n",
    "    stopping_condition=stop_at_2x,\n",
    "    plot_every=None,\n",
    "    plot_final=False,\n",
    ")\n",
    "\n",
    "print(f\"{result_with_stop['total_iterations'] = }\")\n",
    "print(f\"{result_with_stop['final_k_groups'] = }\")\n",
    "\n",
    "# You can also use the stopping condition in sweeps by modifying sweep_config.iters\n",
    "# or adding the stopping condition to merge_iteration calls in the sweep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
