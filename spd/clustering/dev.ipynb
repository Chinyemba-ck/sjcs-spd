{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from muutils.dbg import dbg_auto\n",
    "\n",
    "from spd.clustering.activations import component_activations, process_activations\n",
    "from spd.clustering.merge import compute_merge_costs, merge_iteration\n",
    "from spd.clustering.merge_matrix import GroupMerge\n",
    "from spd.experiments.resid_mlp.resid_mlp_dataset import ResidualMLPDataset\n",
    "from spd.models.component_model import ComponentModel\n",
    "from spd.utils.data_utils import DatasetGeneratedDataLoader\n",
    "\n",
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_model, cfg, path = ComponentModel.from_pretrained(\"wandb:goodfire/spd/runs/dcjm9g2n\")\n",
    "component_model.to(DEVICE);\n",
    "# dbg_auto(component_model)\n",
    "# dbg_auto(cfg)\n",
    "# dbg_auto(path)\n",
    "# dir(component_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# grep_repr((component_model, cfg, path, dir(component_model)), \"_features\")\n",
    "# cfg.task_config\n",
    "# grep_repr(, \"_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES: int = 1000\n",
    "\n",
    "dataset = ResidualMLPDataset(\n",
    "    n_features=component_model.model.config.n_features,\n",
    "    feature_probability=cfg.task_config.feature_probability,\n",
    "    device=DEVICE,\n",
    "    calc_labels=False,  # Our labels will be the output of the target model\n",
    "    label_type=None,\n",
    "    act_fn_name=None,\n",
    "    label_fn_seed=None,\n",
    "    label_coeffs=None,\n",
    "    data_generation_type=cfg.task_config.data_generation_type,\n",
    "    # synced_inputs=synced_inputs,\n",
    ")\n",
    "\n",
    "dbg_auto(dict(\n",
    "    n_features=dataset.n_features,\n",
    "    feature_probability=dataset.feature_probability,\n",
    "    data_generation_type=dataset.data_generation_type,\n",
    "))\n",
    "\n",
    "dataloader = DatasetGeneratedDataLoader(dataset, batch_size=N_SAMPLES, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = component_activations(\n",
    "\tcomponent_model,\n",
    "\tdataloader,\n",
    "\tdevice=DEVICE,\n",
    "\t# threshold=0.1,\n",
    ")\n",
    "\n",
    "dbg_auto(ci);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coa = process_activations(\n",
    "\tci,\n",
    "\tfilter_dead_threshold=0.001,\n",
    "\tplots=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\tF_g := \\frac{\\alpha}{n}\n",
    "\t\\Bigg[\n",
    "\t\td(A(g)) \\cdot Q^T \n",
    "\t\t+ Q \\cdot d(A(g))^T\n",
    "\t\t- \\Big(\n",
    "\t\t\tR \\mathbf{1}^T\n",
    "\t\t\t+ \\mathbf{1} R^T + \\alpha^{-1}\n",
    "\t\t\\Big) \n",
    "\t\t\\odot A(g)\n",
    "\t\\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_ident = GroupMerge.identity(n_components=coa[\"n_components_alive\"])\n",
    "gm_ident.plot(figsize=(10, 2), component_labels=coa[\"labels\"])\n",
    "costs = compute_merge_costs(\n",
    "\tcoact=coa['coactivations'],\n",
    "\tmerges=gm_ident,\n",
    ")\n",
    "plt.matshow(costs.cpu(), cmap='viridis')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_bool = coa['activations'] > 0.01\n",
    "merge_iteration(\n",
    "\tcoact=act_bool.float().T @ act_bool.float(),\n",
    "\tactivation_mask=act_bool,\n",
    "\tcheck_threshold=0.0001,\n",
    "\t# initial_merge=?,\n",
    "\t# rank_cost=lambda _: 100,\n",
    "\trank_cost_fn=lambda _: 0.001,\n",
    "\t# alpha=100,\n",
    "\tpop_component_prob=1,\n",
    "\talpha=0.00001,\n",
    "\titers=200,\n",
    "\tplot_every=20,\n",
    "\tplot_every_min=20,\n",
    "\tcomponent_labels=coa[\"labels\"],\n",
    "\t# plot_every=None,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Example Hyperparameter Sweep Usage\n",
    "\n",
    "# Create sweep configuration\n",
    "import numpy as np\n",
    "\n",
    "from spd.clustering.sweep import SweepConfig, run_hyperparameter_sweep\n",
    "\n",
    "sweep_config = SweepConfig(\n",
    "    # activation_thresholds=[0.001, 0.002, 0.005],\n",
    "    activation_thresholds=np.logspace(-4, -1, 4).tolist(),\n",
    "    # check_thresholds=[0.05, 0.1, 0.2], \n",
    "    check_thresholds=np.logspace(-2, 0, 3).tolist(),\n",
    "    # alphas=[0.1, 1.0, 10.0],\n",
    "    alphas=np.logspace(-3, 0, 4).tolist(),\n",
    "    rank_cost_funcs={\n",
    "        # \"constant_1\": lambda _: 1.0,\n",
    "        # \"constant_0.1\": lambda _: 0.1,\n",
    "        # \"constant_0.001\": lambda _: 0.001,\n",
    "        # \"constant_0.01\": lambda _: 0.01,\n",
    "        # \"constant_0.1\": lambda _: 0.1,\n",
    "        \"constant_1\": lambda _: 1.0,\n",
    "        # \"constant_10\": lambda _: 10.0,\n",
    "        # \"constant_100\": lambda _: 100.0,\n",
    "        \"linear\": lambda c: c,\n",
    "        \"log\": lambda c: np.log(c + 1),\n",
    "    },\n",
    "    iters=50,\n",
    ")\n",
    "\n",
    "# Run sweep\n",
    "sweep_results = run_hyperparameter_sweep(coa['coactivations'], sweep_config)\n",
    "\n",
    "print(f\"\\\\n{len(sweep_results) = }\")\n",
    "for i, result in enumerate(sweep_results[:3]):\n",
    "    print(f\"{i+1}: thresh={result.activation_threshold}, check={result.check_threshold}, Î±={result.alpha}, rank={result.rank_cost_name}\")\n",
    "    print(f\"   iters={result.total_iterations}, groups={result.final_k_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution histories\n",
    "from spd.clustering.sweep import plot_evolution_histories\n",
    "\n",
    "# plot_evolution_histories(\n",
    "#     sweep_results,\n",
    "#     metric='non_diag_costs_min',\n",
    "#     lines_by='alpha',\n",
    "#     cols_by='activation_threshold',\n",
    "#     rows_by='check_threshold',\n",
    "# \tfixed_params={'rank_cost_name': 'constant_0.1'},  # Example fixed parameter\n",
    "# )\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "\tmetric='costs_range',\n",
    "    cols_by='activation_threshold',\n",
    "    rows_by='alpha',\n",
    "    lines_by='check_threshold',\n",
    "\tfixed_params={'rank_cost_name': 'constant_1'},\n",
    ")\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "\tmetric='costs_range',\n",
    "    cols_by='activation_threshold',\n",
    "    rows_by='alpha',\n",
    "    lines_by='check_threshold',\n",
    "\tfixed_params={'rank_cost_name': 'linear'},\n",
    ")\n",
    "\n",
    "plot_evolution_histories(\n",
    "    sweep_results,\n",
    "    # metric='non_diag_costs_min',\n",
    "\tmetric='costs_range',\n",
    "    cols_by='activation_threshold',\n",
    "    rows_by='alpha',\n",
    "    lines_by='check_threshold',\n",
    "\tfixed_params={'rank_cost_name': 'log'},\n",
    ")\n",
    "\n",
    "# plot_evolution_histories(\n",
    "#     sweep_results,\n",
    "#     metric='non_diag_costs_min',\n",
    "#     lines_by='activation_threshold',\n",
    "#     cols_by='rank_cost_name',\n",
    "#     rows_by='check_threshold',\n",
    "# \tfixed_params={'alpha': 0.001},  # Example fixed parameter\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmaps with smart parameter selection\n",
    "from spd.clustering.sweep import create_smart_heatmap\n",
    "\n",
    "create_smart_heatmap(\n",
    "    sweep_results,\n",
    "    statistic_func=lambda r: r.final_k_groups,\n",
    "    statistic_name=\"Final Groups\"\n",
    ")\n",
    "\n",
    "create_smart_heatmap(\n",
    "    sweep_results,\n",
    "    statistic_func=lambda r: r.total_iterations,\n",
    "    statistic_name=\"Total Iterations\"\n",
    ")\n",
    "\n",
    "create_smart_heatmap(\n",
    "    sweep_results,\n",
    "    statistic_func=lambda r: r.non_diag_costs_min[-1] if r.non_diag_costs_min else 0,\n",
    "    statistic_name=\"Final Cost\",\n",
    "    log_scale=True,\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Stopping Condition Examples\n",
    "\n",
    "# Example: Stop when cost reaches 2x original\n",
    "from spd.clustering.sweep import cost_ratio_stopping_condition\n",
    "\n",
    "stop_at_2x = cost_ratio_stopping_condition(2.0)\n",
    "\n",
    "# Run with stopping condition\n",
    "result_with_stop = merge_iteration(\n",
    "    coact=(coa['coactivations'] > 0.002).float().T @ (coa['coactivations'] > 0.002).float(),\n",
    "    activation_mask=coa['coactivations'] > 0.002,\n",
    "    alpha=1.0,\n",
    "    check_threshold=0.1,\n",
    "    stopping_condition=stop_at_2x,\n",
    "    plot_every=None,\n",
    "    plot_final=False,\n",
    ")\n",
    "\n",
    "print(f\"{result_with_stop['total_iterations'] = }\")\n",
    "print(f\"{result_with_stop['final_k_groups'] = }\")\n",
    "\n",
    "# You can also use the stopping condition in sweeps by modifying sweep_config.iters\n",
    "# or adding the stopping condition to merge_iteration calls in the sweep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
